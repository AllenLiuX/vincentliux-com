百度 Deep Speech
在2014年底，吴恩达及团队发布了第一代深度语音识别系统Deep Speech，系统采用了端对端的深度学习技术，当时实现了提高嘈杂环境下的英语识别准确率，实验显示比谷歌、微软及苹果的语音系统的出错率要低10%。
而在2015年8月，百度研究院新增了汉语的识别，准确率高达94%。这也让端到端的深度学习算法成为语音识别提升最重要的手段之一。
2015年9月份的百度世界大会上，吴恩达也在期间展示了新一代的百度语音识别技术，验证在较为嘈杂的情况下，机器识别已经超过人类。
2015年年底，百度研究院又发布了论文推出Deep Speech2，它能够通过深度学习网络识别嘈杂环境下的不同语言，所应用的HPC技术将识别速度提升了7倍。根据研究院的官方消息，HPC技术目前已在今年2月成功应用于深度学习中。



ASRT 是一套基于深度学习实现的语音识别系统，全称为 Auto Speech Recognition Tool，由 AI 柠檬博主开发并在 GitHub 上开源（GPL 3.0 协议）。本项目声学模型通过采用卷积神经网络（CNN）和连接性时序分类（CTC）方法，使用大量中文语音数据集进行训练，将声音转录为中文拼音，并通过语言模型，将拼音序列转换为中文文本。基于该模型，作者在 Windows 平台上实现了一个基于 ASRT 的语音识别应用软件它同样也在 GitHub 上开源了。
ASRT 项目主页：https://asrt.ailemon.me
GitHub 项目地址：https://github.com/nl8590687/ASRT_SpeechRecognition
系统流程
特征提取：将普通的 wav 语音信号通过分帧加窗等操作转换为神经网络需要的二维频谱图像信号，即语谱图。
声学模型：基于 Keras 和 TensorFlow 框架，使用这种参考了 VGG 的深层的卷积神经网络作为网络模型，并训练。
CTC 解码：在语音识别系统的声学模型输出中，往往包含了大量连续重复的符号，因此，我们需要将连续相同的符号合并为同一个符号，然后再去除静音分隔标记符，得到最终实际的语音拼音符号序列。
语言模型：使用统计语言模型，将拼音转换为最终的识别文本并输出。拼音转文本本质被建模为一条隐含马尔可夫链，这种模型有着很高的准确率。
//https://baijiahao.baidu.com/s?id=1625146460946766055&wfr=spider&for=pc


ASRFrame
https://blog.csdn.net/sailist/article/details/95751825
语音到拼音的识别能有大概80%以上的识别率，拼音到汉字可能会更低，但也存在100%识别正确的可能
